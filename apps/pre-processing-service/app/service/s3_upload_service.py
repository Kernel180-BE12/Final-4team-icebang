import time
import asyncio
import aiohttp
from typing import List, Dict
from loguru import logger
from app.errors.CustomException import InvalidItemDataException
from app.model.schemas import RequestS3Upload
from app.utils.s3_upload_util import S3UploadUtil
from app.utils.response import Response


class S3UploadService:
    """6ë‹¨ê³„: í¬ë¡¤ë§ëœ ìƒí’ˆ ì´ë¯¸ì§€ë“¤ê³¼ ë°ì´í„°ë¥¼ S3ì— ì—…ë¡œë“œí•˜ëŠ” ì„œë¹„ìŠ¤"""

    def __init__(self):
        self.s3_util = S3UploadUtil()

    async def upload_crawled_products_to_s3(self, request: RequestS3Upload) -> dict:
        """
        í¬ë¡¤ë§ëœ ìƒí’ˆë“¤ì˜ ì´ë¯¸ì§€ì™€ ë°ì´í„°ë¥¼ S3ì— ì—…ë¡œë“œí•˜ëŠ” ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ (6ë‹¨ê³„)
        """
        keyword = request.keyword  # í‚¤ì›Œë“œ ì¶”ê°€
        crawled_products = request.crawled_products
        base_folder = request.base_folder or "product"  # ğŸ”¸ ê¸°ë³¸ê°’ ë³€ê²½: product-images â†’ product

        logger.info(f"S3 ì—…ë¡œë“œ ì„œë¹„ìŠ¤ ì‹œì‘: keyword='{keyword}', {len(crawled_products)}ê°œ ìƒí’ˆ")

        upload_results = []
        total_success_images = 0
        total_fail_images = 0

        try:
            # HTTP ì„¸ì…˜ì„ ì‚¬ìš©í•œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
            async with aiohttp.ClientSession() as session:

                # ê° ìƒí’ˆë³„ë¡œ ìˆœì°¨ ì—…ë¡œë“œ
                for product_info in crawled_products:
                    product_index = product_info.get("index", 0)
                    product_detail = product_info.get("product_detail")

                    logger.info(
                        f"ìƒí’ˆ {product_index}/{len(crawled_products)} S3 ì—…ë¡œë“œ ì‹œì‘"
                    )

                    # í¬ë¡¤ë§ ì‹¤íŒ¨í•œ ìƒí’ˆì€ ìŠ¤í‚µ
                    if not product_detail or product_info.get("status") != "success":
                        logger.warning(
                            f"ìƒí’ˆ {product_index}: í¬ë¡¤ë§ ì‹¤íŒ¨ë¡œ ì¸í•œ ì—…ë¡œë“œ ìŠ¤í‚µ"
                        )
                        upload_results.append(
                            {
                                "product_index": product_index,
                                "product_title": "Unknown",
                                "status": "skipped",
                                "folder_s3_url": None,
                                "uploaded_images": [],
                                "success_count": 0,
                                "fail_count": 0,
                            }
                        )
                        continue

                    try:
                        # ìƒí’ˆ ì´ë¯¸ì§€ + ë°ì´í„° ì—…ë¡œë“œ (í‚¤ì›Œë“œ ì „ë‹¬ ì¶”ê°€!)
                        # ğŸ”¸ ì „ì²´ í¬ë¡¤ë§ ë°ì´í„°ë¥¼ ì „ë‹¬ (product_detailì´ ì•„ë‹Œ product_info ì „ì²´)
                        upload_result = await self.s3_util.upload_single_product_images(
                            session, product_info, product_index, keyword, base_folder  # product_detail â†’ product_info
                        )

                        upload_results.append(upload_result)
                        total_success_images += upload_result["success_count"]
                        total_fail_images += upload_result["fail_count"]

                        logger.success(
                            f"ìƒí’ˆ {product_index} S3 ì—…ë¡œë“œ ì™„ë£Œ: ì„±ê³µ {upload_result['success_count']}ê°œ, "
                            f"ì‹¤íŒ¨ {upload_result['fail_count']}ê°œ"
                        )

                    except Exception as e:
                        logger.error(f"ìƒí’ˆ {product_index} S3 ì—…ë¡œë“œ ì˜¤ë¥˜: {e}")
                        upload_results.append(
                            {
                                "product_index": product_index,
                                "product_title": product_detail.get("title", "Unknown"),
                                "status": "error",
                                "folder_s3_url": None,
                                "uploaded_images": [],
                                "success_count": 0,
                                "fail_count": 0,
                            }
                        )

                    # ìƒí’ˆê°„ ê°„ê²© (ì„œë²„ ë¶€í•˜ ë°©ì§€)
                    if product_index < len(crawled_products):
                        await asyncio.sleep(1)

            logger.success(
                f"S3 ì—…ë¡œë“œ ì„œë¹„ìŠ¤ ì™„ë£Œ: ì´ ì„±ê³µ ì´ë¯¸ì§€ {total_success_images}ê°œ, ì´ ì‹¤íŒ¨ ì´ë¯¸ì§€ {total_fail_images}ê°œ"
            )

            # ê°„ì†Œí™”ëœ ì‘ë‹µ ë°ì´í„° êµ¬ì„±
            data = {
                "upload_results": upload_results,
                "summary": {
                    "total_products": len(crawled_products),
                    "total_success_images": total_success_images,
                    "total_fail_images": total_fail_images,
                },
                "uploaded_at": time.strftime("%Y-%m-%d %H:%M:%S"),
            }

            message = f"S3 ì—…ë¡œë“œ ì™„ë£Œ: {total_success_images}ê°œ ì´ë¯¸ì§€ ì—…ë¡œë“œ ì„±ê³µ, ìƒí’ˆ ë°ì´í„° JSON íŒŒì¼ í¬í•¨"
            return Response.ok(data, message)

        except Exception as e:
            logger.error(f"S3 ì—…ë¡œë“œ ì„œë¹„ìŠ¤ ì „ì²´ ì˜¤ë¥˜: {e}")
            raise InvalidItemDataException()