import os
import json
import boto3
import aiohttp
import asyncio
from datetime import datetime
from urllib.parse import urlparse
from typing import Dict, Optional
from loguru import logger


class S3UploadUtil:
    """S3 ì—…ë¡œë“œ ì „ìš© ìœ í‹¸ë¦¬í‹° í´ë˜ìŠ¤"""

    def __init__(self):
        # í™˜ê²½ë³€ìˆ˜ì—ì„œ AWS ì„¤ì • ì½ê¸°
        self.aws_access_key = os.getenv("AWS_ACCESS_KEY_ID")
        self.aws_secret_key = os.getenv("AWS_SECRET_ACCESS_KEY")
        self.bucket_name = os.getenv("S3_BUCKET_NAME", "icebang4-dev-bucket")
        self.region = os.getenv("AWS_REGION", "ap-northeast-2")

        if not self.aws_access_key or not self.aws_secret_key:
            raise ValueError(
                "AWS_ACCESS_KEY_IDì™€ AWS_SECRET_ACCESS_KEY í™˜ê²½ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤"
            )

        self.base_url = f"https://{self.bucket_name}.s3.{self.region}.amazonaws.com"

        # S3 í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.s3_client = boto3.client(
            "s3",
            aws_access_key_id=self.aws_access_key,
            aws_secret_access_key=self.aws_secret_key,
            region_name=self.region,
        )

        logger.info(
            f"S3 í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ: bucket={self.bucket_name}, region={self.region}"
        )

    async def download_image(
            self, session: aiohttp.ClientSession, image_url: str
    ) -> Optional[bytes]:
        """ì´ë¯¸ì§€ URLì—ì„œ ì´ë¯¸ì§€ ë°ì´í„° ë‹¤ìš´ë¡œë“œ"""
        try:
            logger.debug(f"ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹œì‘: {image_url}")

            async with session.get(
                    image_url, timeout=aiohttp.ClientTimeout(total=30)
            ) as response:
                if response.status == 200:
                    image_data = await response.read()
                    logger.debug(f"ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {len(image_data)} bytes")
                    return image_data
                else:
                    logger.warning(
                        f"ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {image_url}, status={response.status}"
                    )
                    return None

        except Exception as e:
            logger.error(f"ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {image_url}, error={e}")
            return None

    def get_file_extension(self, image_url: str) -> str:
        """URLì—ì„œ íŒŒì¼ í™•ì¥ì ì¶”ì¶œ"""
        parsed = urlparse(image_url)
        path = parsed.path.lower()

        # ì¼ë°˜ì ì¸ ì´ë¯¸ì§€ í™•ì¥ì í™•ì¸
        for ext in [".jpg", ".jpeg", ".png", ".gif", ".webp"]:
            if ext in path:
                return ext

        # ê¸°ë³¸ê°’
        return ".jpg"

    def get_content_type(self, file_extension: str) -> str:
        """íŒŒì¼ í™•ì¥ìì— ë”°ë¥¸ Content-Type ë°˜í™˜"""
        content_types = {
            ".jpg": "image/jpeg",
            ".jpeg": "image/jpeg",
            ".png": "image/png",
            ".gif": "image/gif",
            ".webp": "image/webp",
        }
        return content_types.get(file_extension, "image/jpeg")

    def upload_to_s3(
            self, data: bytes, s3_key: str, content_type: str = "image/jpeg"
    ) -> bool:
        """S3ì— ë°ì´í„° ì—…ë¡œë“œ (ì´ë¯¸ì§€ ë˜ëŠ” JSON)"""
        try:
            logger.debug(f"S3 ì—…ë¡œë“œ ì‹œì‘: key={s3_key}")

            self.s3_client.put_object(
                Bucket=self.bucket_name,
                Key=s3_key,
                Body=data,
                ContentType=content_type,
            )

            logger.debug(f"S3 ì—…ë¡œë“œ ì™„ë£Œ: key={s3_key}")
            return True

        except Exception as e:
            logger.error(f"S3 ì—…ë¡œë“œ ì˜¤ë¥˜: key={s3_key}, error={e}")
            return False

    def upload_json_to_s3(self, json_data: Dict, s3_key: str) -> bool:
        """JSON ë°ì´í„°ë¥¼ S3ì— ì—…ë¡œë“œ"""
        try:
            json_str = json.dumps(json_data, ensure_ascii=False, indent=2)
            json_bytes = json_str.encode('utf-8')

            return self.upload_to_s3(json_bytes, s3_key, "application/json")

        except Exception as e:
            logger.error(f"JSON S3 ì—…ë¡œë“œ ì˜¤ë¥˜: key={s3_key}, error={e}")
            return False

    def generate_product_folder_name(self, product_index: int, keyword: str) -> str:
        """ìƒí’ˆë³„ í´ë”ëª… ìƒì„± (ì‹œê°„_í‚¤ì›Œë“œ_ë²ˆí˜¸)"""
        # í‚¤ì›Œë“œì—ì„œ íŠ¹ìˆ˜ë¬¸ì ì œê±°
        safe_keyword = (
            keyword.replace("/", "-")
            .replace("\\", "-")
            .replace(" ", "_")
            .replace(":", "-")
            .replace("*", "-")
            .replace("?", "-")
            .replace('"', "-")
            .replace("<", "-")
            .replace(">", "-")
            .replace("|", "-")[:20]  # ê¸¸ì´ ì œí•œ
        )

        # ë‚ ì§œ í˜•ì‹: 20250922
        date_str = datetime.now().strftime("%Y%m%d")

        # í´ë”ëª…: 20250922_í‚¤ì›Œë“œ_1
        folder_name = f"{date_str}_{safe_keyword}_{product_index}"

        return folder_name

    def generate_s3_key(
            self,
            base_folder: str,
            folder_name: str,
            file_name: str,
    ) -> str:
        """S3 í‚¤ ìƒì„±"""
        # ìµœì¢… S3 í‚¤: product/20250922_ì‚°ë¦¬ì˜¤_1/image_001.jpg ë˜ëŠ” product_data.json
        s3_key = f"{base_folder}/{folder_name}/{file_name}"
        return s3_key

    def get_s3_url(self, s3_key: str) -> str:
        """S3 í‚¤ì—ì„œ ì ‘ê·¼ ê°€ëŠ¥í•œ URL ìƒì„±"""
        return f"{self.base_url}/{s3_key}"

    async def upload_single_product_images(
            self,
            session: aiohttp.ClientSession,
            product_info: Dict,  # ğŸ”¸ ì´ë¦„ ë³€ê²½: product_data â†’ product_info (ì „ì²´ í¬ë¡¤ë§ ë°ì´í„°)
            product_index: int,
            keyword: str,  # í‚¤ì›Œë“œ íŒŒë¼ë¯¸í„° ì¶”ê°€
            base_folder: str = "product",  # ğŸ”¸ ê¸°ë³¸ í´ë” ë³€ê²½: product-images â†’ product
    ) -> Dict:
        """ë‹¨ì¼ ìƒí’ˆì˜ ëª¨ë“  ë°ì´í„°(ì´ë¯¸ì§€ + JSON)ë¥¼ S3ì— ì—…ë¡œë“œ"""

        # ğŸ”¸ ì „ì²´ í¬ë¡¤ë§ ë°ì´í„°ì—ì„œ í•„ìš”í•œ ì •ë³´ ì¶”ì¶œ
        product_detail = product_info.get("product_detail", {})
        product_title = product_detail.get("title", "Unknown")
        product_images = product_detail.get("product_images", [])

        uploaded_images = []

        logger.info(
            f"ìƒí’ˆ {product_index} ì—…ë¡œë“œ ì‹œì‘: {len(product_images)}ê°œ ì´ë¯¸ì§€, keyword='{keyword}'"
        )

        # í‚¤ì›Œë“œ ê¸°ë°˜ í´ë”ëª… í•œ ë²ˆë§Œ ìƒì„±
        folder_name = self.generate_product_folder_name(product_index, keyword)

        fail_count = 0
        folder_s3_url = f"{self.base_url}/{base_folder}/{folder_name}"

        # ğŸ†• 1. ë¨¼ì € ìƒí’ˆ ë°ì´í„° JSON íŒŒì¼ ì—…ë¡œë“œ
        try:
            # ì „ì²´ í¬ë¡¤ë§ ë°ì´í„°ë¥¼ JSONìœ¼ë¡œ ì €ì¥ (S3 ì—…ë¡œë“œ ë©”íƒ€ë°ì´í„° ì¶”ê°€)
            product_data_with_meta = {
                **product_info,  # ì „ì²´ í¬ë¡¤ë§ ë°ì´í„° (index, url, product_detail, status, crawled_at í¬í•¨)
                "s3_upload_keyword": keyword,  # ì¶”ê°€ ë©”íƒ€ë°ì´í„°
                "s3_uploaded_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            }

            json_s3_key = self.generate_s3_key(base_folder, folder_name, "product_data.json")

            if self.upload_json_to_s3(product_data_with_meta, json_s3_key):
                logger.success(f"ìƒí’ˆ {product_index} JSON ë°ì´í„° ì—…ë¡œë“œ ì™„ë£Œ")
            else:
                logger.error(f"ìƒí’ˆ {product_index} JSON ë°ì´í„° ì—…ë¡œë“œ ì‹¤íŒ¨")

        except Exception as e:
            logger.error(f"ìƒí’ˆ {product_index} JSON ì—…ë¡œë“œ ì˜¤ë¥˜: {e}")

        # 2. ì´ë¯¸ì§€ ì—…ë¡œë“œ (ê¸°ì¡´ ë¡œì§)
        if not product_images:
            logger.warning(f"ìƒí’ˆ {product_index}: ì—…ë¡œë“œí•  ì´ë¯¸ì§€ê°€ ì—†ìŒ")
            return {
                "product_index": product_index,
                "product_title": product_title,
                "status": "no_images",
                "folder_s3_url": folder_s3_url,
                "uploaded_images": uploaded_images,
                "success_count": 0,
                "fail_count": 0,
            }

        # ê° ì´ë¯¸ì§€ ì—…ë¡œë“œ
        for img_idx, img_info in enumerate(product_images, 1):
            original_url = img_info.get("original_url", "")

            if not original_url:
                logger.warning(f"ìƒí’ˆ {product_index}, ì´ë¯¸ì§€ {img_idx}: URLì´ ì—†ìŒ")
                fail_count += 1
                continue

            try:
                # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
                image_data = await self.download_image(session, original_url)

                if not image_data:
                    fail_count += 1
                    continue

                # S3 í‚¤ ìƒì„± (í‚¤ì›Œë“œ ê¸°ë°˜ í´ë”ëª… ì‚¬ìš©)
                file_extension = self.get_file_extension(original_url)
                image_file_name = f"image_{img_idx:03d}{file_extension}"
                s3_key = self.generate_s3_key(base_folder, folder_name, image_file_name)

                # S3 ì—…ë¡œë“œ
                content_type = self.get_content_type(file_extension)

                if self.upload_to_s3(image_data, s3_key, content_type):
                    s3_url = self.get_s3_url(s3_key)
                    uploaded_images.append(
                        {
                            "index": img_idx,
                            "original_url": original_url,
                            "s3_url": s3_url,
                        }
                    )

                    logger.debug(f"ìƒí’ˆ {product_index}, ì´ë¯¸ì§€ {img_idx} ì—…ë¡œë“œ ì™„ë£Œ")
                else:
                    fail_count += 1

            except Exception as e:
                logger.error(f"ìƒí’ˆ {product_index}, ì´ë¯¸ì§€ {img_idx} ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                fail_count += 1

            # ì´ë¯¸ì§€ ê°„ ê°„ê²© (ì„œë²„ ë¶€í•˜ ë°©ì§€)
            await asyncio.sleep(0.5)

        logger.success(
            f"ìƒí’ˆ {product_index} ì—…ë¡œë“œ ì™„ë£Œ: ì„±ê³µ {len(uploaded_images)}ê°œ, ì‹¤íŒ¨ {fail_count}ê°œ, folder='{folder_name}'"
        )

        return {
            "product_index": product_index,
            "product_title": product_title,
            "status": "completed",
            "folder_s3_url": folder_s3_url,  # ğŸ”¸ í´ë” ì „ì²´ë¥¼ ê°€ë¦¬í‚´ (ì´ë¯¸ì§€ + JSON í¬í•¨)
            "json_s3_url": f"{folder_s3_url}/product_data.json",  # ğŸ†• JSON íŒŒì¼ ì§ì ‘ ë§í¬
            "uploaded_images": uploaded_images,
            "success_count": len(uploaded_images),
            "fail_count": fail_count,
        }